#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åŸºç¡€æ¨¡å‹æµ‹è¯•è„šæœ¬
è®¡ç®— intent_type accuracy, service_type accuracy, joint accuracy
ä¸åŠ è½½LoRAæƒé‡ï¼Œä»…æµ‹è¯•åŸºç¡€æ¨¡å‹æ€§èƒ½
"""

import os
import json
import re
import torch
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForCausalLM

# =====================
# é…ç½®å‚æ•°
# =====================
BASE_MODEL_DIR = "/work/2024/zhulei/intent-driven/qwen3-4b"  # åŸºç¡€æ¨¡å‹è·¯å¾„
TEST_DATA_PATH = "/work/2024/zhulei/intent-driven/test_intent.json"  # æµ‹è¯•æ•°æ®è·¯å¾„
GPU_ID = 2  # ä½¿ç”¨çš„GPU ID

# æ¨ç†å‚æ•°
MAX_NEW_TOKENS = 256
TEMPERATURE = 0.1  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šæ€§çš„è¾“å‡º
TOP_P = 0.9
DO_SAMPLE = True

# =====================
# å·¥å…·å‡½æ•°
# =====================

def load_base_model(base_model_dir, gpu_id=0):
    """åŠ è½½åŸºç¡€æ¨¡å‹ï¼ˆä¸åŠ è½½LoRAæƒé‡ï¼‰"""
    print(f"æ­£åœ¨åŠ è½½åŸºç¡€æ¨¡å‹: {base_model_dir}")
    
    if torch.cuda.is_available():
        device = f"cuda:{gpu_id}"
        torch.cuda.set_device(gpu_id)
        dtype = torch.float16
        device_map = {"": device}
    else:
        device = "cpu"
        dtype = torch.float32
        device_map = "cpu"
    
    # åŠ è½½tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
        base_model_dir,
        trust_remote_code=True
    )
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
        tokenizer.pad_token_id = tokenizer.eos_token_id
    
    # åŠ è½½åŸºç¡€æ¨¡å‹
    print("åŠ è½½åŸºç¡€æ¨¡å‹...")
    model = AutoModelForCausalLM.from_pretrained(
        base_model_dir,
        torch_dtype=dtype,
        device_map=device_map,
        trust_remote_code=True
    )
    
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    print("âœ… åŸºç¡€æ¨¡å‹åŠ è½½å®Œæˆ")
    return tokenizer, model

def create_prompt(input_text):
    """æ ¹æ®è¾“å…¥æ–‡æœ¬æ„é€ promptï¼ˆä½¿ç”¨messagesæ ¼å¼ï¼‰"""
    # æ·»åŠ system promptæ¥æ˜ç¡®è¦æ±‚è¾“å‡ºJSONæ ¼å¼
    # æ³¨æ„ï¼šåŸºç¡€æ¨¡å‹å¯èƒ½æ²¡æœ‰ç»è¿‡è®­ç»ƒï¼Œéœ€è¦æ˜ç¡®çš„æŒ‡ä»¤æ¥å¼•å¯¼è¾“å‡ºæ ¼å¼
    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªæ„å›¾è¯†åˆ«åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œæå–intent_typeå’Œservice_typeï¼Œå¹¶ä»¥JSONæ ¼å¼è¾“å‡ºï¼š{\"intent_type\": \"...\", \"service_type\": \"...\"}ã€‚åªè¾“å‡ºJSONï¼Œä¸è¦è¾“å‡ºå…¶ä»–è§£é‡Šæˆ–æ¨ç†è¿‡ç¨‹ã€‚"
        },
        {
            "role": "user",
            "content": input_text
        }
    ]
    return messages

def parse_model_output(output_text, input_text):
    """
    ä»æ¨¡å‹è¾“å‡ºä¸­è§£æintent_typeå’Œservice_type
    æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼š
    1. JSONæ ¼å¼: {"intent_type": "...", "service_type": "..."}
    2. è‡ªç„¶è¯­è¨€æ ¼å¼: intent_type: xxx, service_type: xxx
    3. å…¶ä»–æ ¼å¼
    """
    intent_type = None
    service_type = None
    
    # å·²çŸ¥çš„æ‰€æœ‰å¯èƒ½å€¼
    known_intents = ["slice_create", "route_preference", "slice_qos_modify", "access_control"]
    known_services = [
        "realtime_video", "realtime_voice_call", "realtime_xr_gaming",
        "streaming_live", "streaming_video", "iot_sensor", 
        "urllc_control", "internet_access"
    ]
    
    # æ–¹æ³•1: å°è¯•æå–å®Œæ•´çš„JSONæ ¼å¼
    # åŒ¹é… { ... "intent_type": "xxx" ... "service_type": "xxx" ... }
    json_patterns = [
        r'\{[^{}]*"intent_type"\s*:\s*"([^"]+)"[^{}]*"service_type"\s*:\s*"([^"]+)"[^{}]*\}',
        r'\{[^{}]*"service_type"\s*:\s*"([^"]+)"[^{}]*"intent_type"\s*:\s*"([^"]+)"[^{}]*\}',
    ]
    
    for pattern in json_patterns:
        json_match = re.search(pattern, output_text, re.IGNORECASE | re.DOTALL)
        if json_match:
            if "intent_type" in pattern:
                intent_type = json_match.group(1).strip()
                service_type = json_match.group(2).strip()
            else:
                service_type = json_match.group(1).strip()
                intent_type = json_match.group(2).strip()
            break
    
    # æ–¹æ³•2: å°è¯•æå–å•ç‹¬çš„JSONå­—æ®µ
    if intent_type is None:
        intent_json_pattern = r'"intent_type"\s*:\s*"([^"]+)"'
        intent_match = re.search(intent_json_pattern, output_text, re.IGNORECASE)
        if intent_match:
            intent_type = intent_match.group(1).strip()
    
    if service_type is None:
        service_json_pattern = r'"service_type"\s*:\s*"([^"]+)"'
        service_match = re.search(service_json_pattern, output_text, re.IGNORECASE)
        if service_match:
            service_type = service_match.group(1).strip()
    
    # æ–¹æ³•3: å°è¯•æå–é”®å€¼å¯¹æ ¼å¼ (intent_type: xxx æˆ– intent_type=xxx)
    if intent_type is None:
        intent_patterns = [
            r'intent_type["\s:ï¼š=]+\s*([a-z_]+)',
            r'intent["\s:ï¼š=]+\s*([a-z_]+)',
        ]
        for pattern in intent_patterns:
            intent_match = re.search(pattern, output_text, re.IGNORECASE)
            if intent_match:
                candidate = intent_match.group(1).strip()
                if candidate in known_intents:
                    intent_type = candidate
                    break
    
    if service_type is None:
        service_patterns = [
            r'service_type["\s:ï¼š=]+\s*([a-z_]+)',
            r'service["\s:ï¼š=]+\s*([a-z_]+)',
        ]
        for pattern in service_patterns:
            service_match = re.search(pattern, output_text, re.IGNORECASE)
            if service_match:
                candidate = service_match.group(1).strip()
                if candidate in known_services:
                    service_type = candidate
                    break
    
    # æ–¹æ³•4: åœ¨æ•´ä¸ªè¾“å‡ºä¸­æœç´¢å·²çŸ¥çš„å€¼ï¼ˆä½œä¸ºæœ€åæ‰‹æ®µï¼‰
    if intent_type is None:
        for intent in known_intents:
            # ä½¿ç”¨å•è¯è¾¹ç•Œç¡®ä¿å®Œæ•´åŒ¹é…
            pattern = r'\b' + re.escape(intent) + r'\b'
            if re.search(pattern, output_text, re.IGNORECASE):
                intent_type = intent
                break
    
    if service_type is None:
        for service in known_services:
            # ä½¿ç”¨å•è¯è¾¹ç•Œç¡®ä¿å®Œæ•´åŒ¹é…
            pattern = r'\b' + re.escape(service) + r'\b'
            if re.search(pattern, output_text, re.IGNORECASE):
                service_type = service
                break
    
    return intent_type, service_type

def infer(model, tokenizer, input_text):
    """å¯¹è¾“å…¥è¿›è¡Œæ¨ç†"""
    # æ„é€ messages
    messages = create_prompt(input_text)
    
    # ä½¿ç”¨tokenizerçš„apply_chat_templateæ ¼å¼åŒ–
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    # Tokenize
    inputs = tokenizer(text, return_tensors="pt").to(model.device)
    
    # æ¨ç†
    with torch.inference_mode():
        outputs = model.generate(
            **inputs,
            max_new_tokens=MAX_NEW_TOKENS,
            do_sample=DO_SAMPLE,
            temperature=TEMPERATURE,
            top_p=TOP_P,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id
        )
    
    # è§£ç è¾“å‡ºï¼ˆåªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†ï¼‰
    input_length = inputs['input_ids'].shape[1]
    generated_tokens = outputs[0][input_length:]
    output_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)
    
    # æˆªæ–­è¾“å‡ºï¼šå¦‚æœè¾“å‡ºåŒ…å«JSONï¼Œåªä¿ç•™JSONéƒ¨åˆ†ï¼›å¦åˆ™æˆªæ–­åˆ°ç¬¬ä¸€ä¸ªæ¢è¡Œæˆ–åœæ­¢è¯
    # åœæ­¢è¯åˆ—è¡¨ï¼ˆæ¨¡å‹å¯èƒ½åœ¨è¿™äº›è¯åç»§ç»­ç”Ÿæˆæ— å…³å†…å®¹ï¼‰
    stop_phrases = ["\n\n", "\nç”¨æˆ·", "\nå—¯", "\nå¥½çš„", "\né¦–å…ˆ", "\næˆ‘", "\nè¿™", "\næ ¹æ®", "<|endoftext|>"]
    
    # æ–¹æ³•1: å°è¯•æå–å®Œæ•´çš„JSONå¯¹è±¡ï¼ˆæ”¯æŒåµŒå¥—å’Œæ¢è¡Œï¼‰
    # åŒ¹é…ä»ç¬¬ä¸€ä¸ª { å¼€å§‹åˆ°åŒ¹é…çš„ } ç»“æŸçš„å®Œæ•´JSON
    json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*"intent_type"[^{}]*(?:\{[^{}]*\}[^{}]*)*"service_type"[^{}]*(?:\{[^{}]*\}[^{}]*)*\}|"intent_type"[^{}]*"service_type"[^{}]*\}'
    json_match = re.search(json_pattern, output_text, re.IGNORECASE | re.DOTALL)
    
    if json_match:
        # å¦‚æœæ‰¾åˆ°JSONï¼Œå°è¯•æå–å®Œæ•´çš„JSONå¯¹è±¡
        json_start = output_text.find('{')
        if json_start != -1:
            # ä»ç¬¬ä¸€ä¸ª { å¼€å§‹ï¼Œå°è¯•æ‰¾åˆ°åŒ¹é…çš„ }
            brace_count = 0
            json_end = json_start
            for i in range(json_start, min(json_start + 500, len(output_text))):  # é™åˆ¶æœç´¢èŒƒå›´
                if output_text[i] == '{':
                    brace_count += 1
                elif output_text[i] == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        json_end = i + 1
                        break
            if brace_count == 0:
                output_text = output_text[json_start:json_end]
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„ }ï¼Œä½¿ç”¨æ­£åˆ™åŒ¹é…çš„ç»“æœ
                output_text = json_match.group(0)
        else:
            output_text = json_match.group(0)
    else:
        # æ–¹æ³•2: åœ¨ç¬¬ä¸€ä¸ªåœæ­¢è¯å¤„æˆªæ–­
        for stop_phrase in stop_phrases:
            if stop_phrase in output_text:
                output_text = output_text.split(stop_phrase)[0]
                break
        # å¦‚æœè¾“å‡ºå¤ªé•¿ä¸”æ²¡æœ‰æ‰¾åˆ°åœæ­¢è¯ï¼Œæˆªæ–­åˆ°åˆç†é•¿åº¦
        if len(output_text) > 300:
            output_text = output_text[:300]
    
    return output_text.strip()

def load_test_data(test_data_path):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    print(f"æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ®: {test_data_path}")
    with open(test_data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    print(f"æµ‹è¯•é›†å¤§å°: {len(data)} æ¡")
    return data

def calculate_metrics(results):
    """è®¡ç®—å‡†ç¡®ç‡æŒ‡æ ‡"""
    total = len(results)
    intent_correct = 0
    service_correct = 0
    joint_correct = 0
    
    for result in results:
        if result['intent_pred'] == result['intent_true']:
            intent_correct += 1
        if result['service_pred'] == result['service_true']:
            service_correct += 1
        if (result['intent_pred'] == result['intent_true'] and 
            result['service_pred'] == result['service_true']):
            joint_correct += 1
    
    intent_acc = intent_correct / total if total > 0 else 0
    service_acc = service_correct / total if total > 0 else 0
    joint_acc = joint_correct / total if total > 0 else 0
    
    return {
        'intent_accuracy': intent_acc,
        'service_accuracy': service_acc,
        'joint_accuracy': joint_acc,
        'intent_correct': intent_correct,
        'service_correct': service_correct,
        'joint_correct': joint_correct,
        'total': total
    }

def main():
    print("=" * 60)
    print("ğŸš€ åŸºç¡€æ¨¡å‹æµ‹è¯•å¼€å§‹")
    print("=" * 60)
    
    # æ£€æŸ¥è·¯å¾„
    if not os.path.exists(BASE_MODEL_DIR):
        raise FileNotFoundError(f"åŸºç¡€æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {BASE_MODEL_DIR}")
    
    if not os.path.exists(TEST_DATA_PATH):
        raise FileNotFoundError(f"æµ‹è¯•æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {TEST_DATA_PATH}")
    
    # åŠ è½½æ¨¡å‹
    tokenizer, model = load_base_model(BASE_MODEL_DIR, GPU_ID)
    print(f"æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}\n")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_data = load_test_data(TEST_DATA_PATH)
    
    # è¿›è¡Œæµ‹è¯•
    print("å¼€å§‹æµ‹è¯•...")
    print("-" * 60)
    
    results = []
    for idx, item in enumerate(test_data, 1):
        input_text = item['input']
        intent_true = item['intent_type']
        service_true = item['service_type']
        
        # æ¨ç†
        try:
            output_text = infer(model, tokenizer, input_text)
            intent_pred, service_pred = parse_model_output(output_text, input_text)
        except Exception as e:
            print(f"âš ï¸  ç¬¬ {idx} æ¡æµ‹è¯•å‡ºé”™: {e}")
            intent_pred = None
            service_pred = None
            output_text = ""
        
        # è®°å½•ç»“æœ
        result = {
            'idx': idx,
            'input': input_text,
            'intent_true': intent_true,
            'intent_pred': intent_pred,
            'service_true': service_true,
            'service_pred': service_pred,
            'output': output_text,
            'intent_correct': intent_pred == intent_true,
            'service_correct': service_pred == service_true,
            'joint_correct': (intent_pred == intent_true and service_pred == service_true)
        }
        results.append(result)
        
        # æ˜¾ç¤ºè¿›åº¦
        if idx % 10 == 0:
            print(f"å·²æµ‹è¯• {idx}/{len(test_data)} æ¡...")
    
    print("-" * 60)
    print("æµ‹è¯•å®Œæˆï¼\n")
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_metrics(results)
    
    # æ˜¾ç¤ºç»“æœ
    print("=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœï¼ˆåŸºç¡€æ¨¡å‹ï¼‰")
    print("=" * 60)
    print(f"æ€»æµ‹è¯•æ ·æœ¬æ•°: {metrics['total']}")
    print(f"\nIntent Type Accuracy: {metrics['intent_accuracy']:.4f} ({metrics['intent_correct']}/{metrics['total']})")
    print(f"Service Type Accuracy: {metrics['service_accuracy']:.4f} ({metrics['service_correct']}/{metrics['total']})")
    print(f"Joint Accuracy: {metrics['joint_accuracy']:.4f} ({metrics['joint_correct']}/{metrics['total']})")
    print("=" * 60)
    
    # æ˜¾ç¤ºé”™è¯¯æ ·æœ¬
    print("\nâŒ é”™è¯¯æ ·æœ¬åˆ†æ:")
    print("-" * 60)
    
    intent_errors = [r for r in results if not r['intent_correct']]
    service_errors = [r for r in results if not r['service_correct']]
    joint_errors = [r for r in results if not r['joint_correct']]
    
    print(f"\nIntenté”™è¯¯ ({len(intent_errors)} ä¸ª):")
    for r in intent_errors[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  è¾“å…¥: {r['input'][:50]}...")
        print(f"  çœŸå®: {r['intent_true']}, é¢„æµ‹: {r['intent_pred']}")
        print(f"  è¾“å‡º: {r['output'][:100]}...")
        print()
    
    print(f"\nServiceé”™è¯¯ ({len(service_errors)} ä¸ª):")
    for r in service_errors[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  è¾“å…¥: {r['input'][:50]}...")
        print(f"  çœŸå®: {r['service_true']}, é¢„æµ‹: {r['service_pred']}")
        print(f"  è¾“å‡º: {r['output'][:100]}...")
        print()
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_file = "test_base_model_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'model_type': 'base_model',
            'base_model_dir': BASE_MODEL_DIR,
            'metrics': metrics,
            'results': results
        }, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    main()




