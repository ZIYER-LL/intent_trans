#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Policyæ¨¡å‹æµ‹è¯•è„šæœ¬
è®¡ç®— policy å‚æ•°çš„è¯¯å·®æŒ‡æ ‡ï¼šMAE, MSE, RMSE, ç›¸å¯¹è¯¯å·®ç­‰
"""

import os
import json
import re
import torch
import numpy as np
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

# =====================
# é…ç½®å‚æ•°
# =====================
BASE_MODEL_DIR = "/work/2024/zhulei/intent-driven/qwen3-4b"  # åŸºç¡€æ¨¡å‹è·¯å¾„
LORA_MODEL_DIR = "/work/2024/zhulei/intent-driven/outputs/qwen3-4b-lora-policy"  # LoRAæ¨¡å‹è·¯å¾„
TEST_DATA_PATH = "/work/2024/zhulei/intent-driven/test_policy.json"  # æµ‹è¯•æ•°æ®è·¯å¾„
GPU_ID = 7  # ä½¿ç”¨çš„GPU ID

# æ¨ç†å‚æ•°
MAX_NEW_TOKENS = 512
TEMPERATURE = 0.1  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šæ€§çš„è¾“å‡º
TOP_P = 0.9
DO_SAMPLE = True

# Policyå‚æ•°åç§°
POLICY_PARAMS = [
    "latency_ms",
    "jitter_ms", 
    "packet_loss_rate",
    "bandwidth_kbps",
    "reliability",
    "priority"
]

# =====================
# 3GPPæ ‡å‡†è§„åˆ™ä¹¦ - å„æœåŠ¡ç±»å‹çš„Policyå‚æ•°æœ‰æ•ˆèŒƒå›´
# =====================

# åŸºäº 3GPP TS 26.114ã€TS 22.261ã€å®æ—¶è§†é¢‘å…¸å‹æœåŠ¡è¦æ±‚
REALTIME_VIDEO_RULEBOOK = {
    "latency_ms": [40, 120],
    "jitter_ms": [1, 20],
    "packet_loss_rate": [0.001, 0.02],
    "bandwidth_kbps": [1500, 6000],
    "reliability": [0.999, 0.9999],
    "priority": 2
}

# åŸºäº3GPP TS 26.114ï¼ˆVoIP/IMSï¼‰ã€TS 22.105ã€TS 22.261æ±‡æ€»
REALTIME_VOICE_CALL_RULEBOOK = {
    "latency_ms": [50, 150],
    "jitter_ms": [1, 30],
    "packet_loss_rate": [0.001, 0.03],
    "bandwidth_kbps": [20, 100],
    "reliability": [0.98, 0.999],
    "priority": 2
}

# åŸºäº3GPP TS 22.261ï¼ˆXR Requirementsï¼‰ã€3GPP TS 26.118ï¼ˆXR streamingï¼‰ITU-T G.1035ï¼ˆCloud Gaming QoEï¼‰
REALTIME_XR_GAMING_RULEBOOK = {
    "latency_ms": [5, 25],
    "jitter_ms": [1, 10],
    "packet_loss_rate": [0.0005, 0.01],
    "bandwidth_kbps": [50000, 150000],  # 50Mbps~150Mbps
    "reliability": [0.999, 0.9999],
    "priority": 2
}

# åŸºäº3GPP TS 26.234ï¼ˆProgressive/Adaptive Streamingï¼‰ã€DASHï¼ˆISO/IEC 23009-1ï¼‰è§†é¢‘æµæ ‡å‡†
STREAMING_VIDEO_RULEBOOK = {
    "latency_ms": [100, 300],
    "jitter_ms": [5, 50],
    "packet_loss_rate": [0.001, 0.05],
    "bandwidth_kbps": [3000, 12000],   # 3Mbps~12Mbps
    "reliability": [0.99, 0.999],
    "priority": 4
}

# åŸºäº3GPP TS 26.235ï¼ˆAdaptive Streamingï¼‰ã€TS 22.261ï¼ˆMedia services requirementsï¼‰
STREAMING_LIVE_RULEBOOK = {
    "latency_ms": [80, 200],
    "jitter_ms": [5, 20],
    "packet_loss_rate": [0.001, 0.03],
    "bandwidth_kbps": [8000, 20000],  # 8Mbps~20Mbps
    "reliability": [0.99, 0.999],
    "priority": 3
}

# åŸºäº3GPP TS 22.261ï¼ˆData-centric servicesï¼‰
FILE_TRANSFER_RULEBOOK = {
    "latency_ms": [80, 300],
    "jitter_ms": [10, 100],
    "packet_loss_rate": [0.001, 0.05],
    "bandwidth_kbps": [5000, 20000],
    "reliability": [0.999, 0.99999],
    "priority": 5
}

# åŸºäº3GPP TS 22.104ï¼ˆå·¥ä¸š IoTï¼‰ã€TS 22.261ï¼ˆ5G/6G æœåŠ¡éœ€æ±‚ï¼‰ã€TS 23.501ï¼ˆQoS Frameworkï¼‰
IOT_SENSOR_RULEBOOK = {
    "latency_ms": [10, 80],
    "jitter_ms": [1, 20],
    "packet_loss_rate": [0.0001, 0.01],
    "bandwidth_kbps": [50, 500],
    "reliability": [0.999, 0.99999],
    "priority": 3
}

# åŸºäº3GPP TS 22.261ï¼ˆeMBB service requirementsï¼‰ã€3GPP TS 23.501ï¼ˆQoS Frameworkï¼‰
INTERNET_ACCESS_RULEBOOK = {
    "latency_ms": [50, 300],
    "jitter_ms": [10, 80],
    "packet_loss_rate": [0.001, 0.05],
    "bandwidth_kbps": [10000, 50000],
    "reliability": [0.99, 0.999],
    "priority": 4
}

# åŸºäº3GPP TS 22.104ï¼ˆMission Critical servicesï¼‰ã€3GPP TS 22.261ï¼ˆService requirements for 5G/6Gï¼‰ã€3GPP TS 23.501ï¼ˆQoS Frameworkï¼‰
URLLC_CONTROL_RULEBOOK = {
    "latency_ms": [1, 10],
    "jitter_ms": [0.1, 2],
    "packet_loss_rate": [0.00001, 0.001],
    "bandwidth_kbps": [100, 1000],
    "reliability": [0.99999, 0.999999],
    "priority": 1
}

# æœåŠ¡ç±»å‹åˆ°è§„åˆ™ä¹¦çš„æ˜ å°„
SERVICE_RULEBOOK_MAP = {
    "realtime_video": REALTIME_VIDEO_RULEBOOK,
    "realtime_voice_call": REALTIME_VOICE_CALL_RULEBOOK,
    "realtime_xr_gaming": REALTIME_XR_GAMING_RULEBOOK,
    "streaming_video": STREAMING_VIDEO_RULEBOOK,
    "streaming_live": STREAMING_LIVE_RULEBOOK,
    "file_transfer": FILE_TRANSFER_RULEBOOK,
    "iot_sensor": IOT_SENSOR_RULEBOOK,
    "internet_access": INTERNET_ACCESS_RULEBOOK,
    "urllc_control": URLLC_CONTROL_RULEBOOK,
}

# =====================
# å·¥å…·å‡½æ•°
# =====================

def load_model_with_lora(base_model_dir, lora_model_dir, gpu_id=0):
    """åŠ è½½åŸºç¡€æ¨¡å‹å’ŒLoRAæƒé‡"""
    print(f"æ­£åœ¨åŠ è½½åŸºç¡€æ¨¡å‹: {base_model_dir}")
    
    if torch.cuda.is_available():
        device = f"cuda:{gpu_id}"
        torch.cuda.set_device(gpu_id)
        dtype = torch.float16
        device_map = {"": device}
    else:
        device = "cpu"
        dtype = torch.float32
        device_map = "cpu"
    
    # åŠ è½½tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
        base_model_dir,
        trust_remote_code=True
    )
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
        tokenizer.pad_token_id = tokenizer.eos_token_id
    
    # åŠ è½½åŸºç¡€æ¨¡å‹
    print("åŠ è½½åŸºç¡€æ¨¡å‹...")
    base_model = AutoModelForCausalLM.from_pretrained(
        base_model_dir,
        torch_dtype=dtype,
        device_map=device_map,
        trust_remote_code=True
    )
    
    # åŠ è½½LoRAæƒé‡
    if os.path.exists(lora_model_dir):
        print(f"åŠ è½½LoRAæƒé‡: {lora_model_dir}")
        model = PeftModel.from_pretrained(base_model, lora_model_dir)
        print("âœ… LoRAæ¨¡å‹åŠ è½½å®Œæˆ")
    else:
        print(f"âš ï¸  LoRAè·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹: {lora_model_dir}")
        model = base_model
    
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    return tokenizer, model

def create_prompt(user_intent):
    """æ ¹æ®ç”¨æˆ·æ„å›¾æ„é€ promptï¼ˆä½¿ç”¨messagesæ ¼å¼ï¼‰"""
    messages = [
        {
            "role": "user",
            "content": user_intent
        }
    ]
    return messages

def parse_policy_output(output_text):
    """
    ä»æ¨¡å‹è¾“å‡ºä¸­è§£æpolicy JSON
    æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼š
    1. çº¯JSONæ ¼å¼: {"latency_ms": 70, "jitter_ms": 10, ...}
    2. å¸¦è¯´æ˜çš„JSON: æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œpolicyä¸º: {"latency_ms": 70, ...}
    3. ä»£ç å—æ ¼å¼: ```json\n{...}\n```
    """
    policy = None
    
    # æ–¹æ³•1: å°è¯•æå–å®Œæ•´çš„JSONå¯¹è±¡
    # åŒ¹é… { ... "latency_ms": xxx ... } æ ¼å¼
    json_pattern = r'\{[^{}]*"latency_ms"[^{}]*\}'
    
    # å°è¯•åŒ¹é…æ›´å¤æ‚çš„åµŒå¥—JSONï¼ˆå¯èƒ½åŒ…å«å¤šè¡Œï¼‰
    json_patterns = [
        r'\{[^{}]*(?:"latency_ms"|"jitter_ms"|"packet_loss_rate"|"bandwidth_kbps"|"reliability"|"priority")[^{}]*\}',
        r'\{.*?"latency_ms".*?\}',
    ]
    
    for pattern in json_patterns:
        matches = re.finditer(pattern, output_text, re.DOTALL | re.IGNORECASE)
        for match in matches:
            try:
                candidate = json.loads(match.group(0))
                # éªŒè¯æ˜¯å¦åŒ…å«policyå‚æ•°
                if any(key in candidate for key in POLICY_PARAMS):
                    policy = candidate
                    break
            except json.JSONDecodeError:
                continue
        if policy:
            break
    
    # æ–¹æ³•2: å°è¯•æå–ä»£ç å—ä¸­çš„JSON
    if policy is None:
        code_block_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
        matches = re.finditer(code_block_pattern, output_text, re.DOTALL | re.IGNORECASE)
        for match in matches:
            try:
                candidate = json.loads(match.group(1))
                if any(key in candidate for key in POLICY_PARAMS):
                    policy = candidate
                    break
            except json.JSONDecodeError:
                continue
    
    # æ–¹æ³•3: å°è¯•ç›´æ¥è§£ææ•´ä¸ªè¾“å‡º
    if policy is None:
        try:
            candidate = json.loads(output_text.strip())
            if isinstance(candidate, dict) and any(key in candidate for key in POLICY_PARAMS):
                policy = candidate
        except json.JSONDecodeError:
            pass
    
    # æ–¹æ³•4: å°è¯•æå–æ‰€æœ‰å¯èƒ½çš„JSONå¯¹è±¡
    if policy is None:
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„JSONå¯¹è±¡
        json_objects = re.findall(r'\{[^{}]*(?:"latency_ms"|"jitter_ms"|"packet_loss_rate"|"bandwidth_kbps"|"reliability"|"priority")[^{}]*\}', 
                                  output_text, re.DOTALL | re.IGNORECASE)
        for obj_str in json_objects:
            try:
                candidate = json.loads(obj_str)
                if isinstance(candidate, dict) and any(key in candidate for key in POLICY_PARAMS):
                    policy = candidate
                    break
            except json.JSONDecodeError:
                continue
    
    return policy

def check_param_in_range(param_name, param_value, rulebook):
    """
    æ£€æŸ¥å‚æ•°å€¼æ˜¯å¦åœ¨è§„åˆ™ä¹¦å®šä¹‰çš„æœ‰æ•ˆèŒƒå›´å†…
    
    Args:
        param_name: å‚æ•°åç§°
        param_value: å‚æ•°å€¼
        rulebook: è§„åˆ™ä¹¦å­—å…¸
    
    Returns:
        bool: Trueè¡¨ç¤ºåœ¨èŒƒå›´å†…ï¼ŒFalseè¡¨ç¤ºä¸åœ¨èŒƒå›´å†…
    """
    if param_name not in rulebook:
        return None  # è§„åˆ™ä¹¦ä¸­æ²¡æœ‰å®šä¹‰è¯¥å‚æ•°
    
    rule = rulebook[param_name]
    
    # å¦‚æœè§„åˆ™æ˜¯å•ä¸ªå€¼ï¼ˆå¦‚priorityï¼‰ï¼Œåˆ™å¿…é¡»å®Œå…¨åŒ¹é…
    if not isinstance(rule, list):
        return param_value == rule
    
    # å¦‚æœè§„åˆ™æ˜¯èŒƒå›´ [min, max]
    if isinstance(rule, list) and len(rule) == 2:
        min_val, max_val = rule[0], rule[1]
        return min_val <= param_value <= max_val
    
    return None

def check_policy_compliance(policy, service_type):
    """
    æ£€æŸ¥policyæ˜¯å¦ç¬¦åˆå¯¹åº”æœåŠ¡ç±»å‹çš„è§„åˆ™ä¹¦è¦æ±‚
    
    Args:
        policy: policyå­—å…¸
        service_type: æœåŠ¡ç±»å‹
    
    Returns:
        dict: åŒ…å«æ¯ä¸ªå‚æ•°çš„åˆè§„æ€§æ£€æŸ¥ç»“æœ
    """
    compliance = {}
    
    # è·å–å¯¹åº”çš„è§„åˆ™ä¹¦
    rulebook = SERVICE_RULEBOOK_MAP.get(service_type)
    if rulebook is None:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„è§„åˆ™ä¹¦ï¼Œè¿”å›Noneè¡¨ç¤ºæ— æ³•æ£€æŸ¥
        return None
    
    # æ£€æŸ¥æ¯ä¸ªå‚æ•°
    for param in POLICY_PARAMS:
        if param in policy:
            param_value = float(policy[param])
            is_compliant = check_param_in_range(param, param_value, rulebook)
            compliance[param] = {
                'value': param_value,
                'in_range': is_compliant,
                'rule': rulebook.get(param)
            }
        else:
            compliance[param] = {
                'value': None,
                'in_range': False,  # ç¼ºå°‘å‚æ•°è§†ä¸ºä¸åˆè§„
                'rule': rulebook.get(param)
            }
    
    # è®¡ç®—æ•´ä½“åˆè§„ç‡
    total_params = len([p for p in POLICY_PARAMS if p in policy])
    compliant_params = sum(1 for p in POLICY_PARAMS if p in policy and compliance.get(p, {}).get('in_range') == True)
    compliance['overall_compliance_rate'] = compliant_params / total_params if total_params > 0 else 0
    compliance['all_compliant'] = all(compliance.get(p, {}).get('in_range') == True for p in POLICY_PARAMS if p in policy)
    
    return compliance

def infer(model, tokenizer, user_intent):
    """å¯¹è¾“å…¥è¿›è¡Œæ¨ç†"""
    # æ„é€ messages
    messages = create_prompt(user_intent)
    
    # ä½¿ç”¨tokenizerçš„apply_chat_templateæ ¼å¼åŒ–
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    # Tokenize
    inputs = tokenizer(text, return_tensors="pt").to(model.device)
    
    # æ¨ç†
    with torch.inference_mode():
        outputs = model.generate(
            **inputs,
            max_new_tokens=MAX_NEW_TOKENS,
            do_sample=DO_SAMPLE,
            temperature=TEMPERATURE,
            top_p=TOP_P,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id
        )
    
    # è§£ç è¾“å‡ºï¼ˆåªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†ï¼‰
    input_length = inputs['input_ids'].shape[1]
    generated_tokens = outputs[0][input_length:]
    output_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)
    
    return output_text

def load_test_data(test_data_path):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    print(f"æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ®: {test_data_path}")
    with open(test_data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    print(f"æµ‹è¯•é›†å¤§å°: {len(data)} æ¡")
    return data

def extract_policy_from_data(item):
    """ä»æ•°æ®é¡¹ä¸­æå–ç”¨æˆ·æ„å›¾ã€æœåŠ¡ç±»å‹å’ŒæœŸæœ›çš„policy"""
    service_type = None
    policy = {}
    
    if "instruction" in item:
        # æ ¼å¼: {instruction: {user_intent: ..., service_type: ..., intent_type: ...}}
        user_intent = item["instruction"].get("user_intent", "")
        service_type = item["instruction"].get("service_type", None)
        intent_type = item["instruction"].get("intent_type", None)
        
        # å¦‚æœæœ‰outputå­—æ®µï¼Œæå–æœŸæœ›çš„policyï¼ˆç”¨äºæœ‰æ ‡å‡†ç­”æ¡ˆçš„æƒ…å†µï¼‰
        if "output" in item:
            policy = item["output"].get("policy", {})
    elif "messages" in item:
        # æ ¼å¼: {messages: [{role: "user", content: ...}, {role: "assistant", content: ...}]}
        user_intent = ""
        for msg in item["messages"]:
            if msg["role"] == "user":
                user_intent = msg["content"]
            elif msg["role"] == "assistant":
                try:
                    content = msg["content"]
                    # å°è¯•è§£æJSON
                    if isinstance(content, str):
                        policy = json.loads(content)
                    elif isinstance(content, dict):
                        policy = content
                except (json.JSONDecodeError, TypeError):
                    pass
    else:
        # å…¶ä»–å¯èƒ½çš„æ ¼å¼
        user_intent = item.get("user_intent", item.get("input", ""))
        service_type = item.get("service_type", None)
        policy = item.get("policy", item.get("output", {}))
        # å¦‚æœoutputæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
        if isinstance(policy, str):
            try:
                policy = json.loads(policy)
            except json.JSONDecodeError:
                policy = {}
    
    return user_intent, service_type, policy

def calculate_metrics(results):
    """è®¡ç®—policyå‚æ•°çš„è¯¯å·®æŒ‡æ ‡å’Œåˆè§„æ€§æŒ‡æ ‡"""
    total = len(results)
    
    # ç»Ÿè®¡è§£ææˆåŠŸçš„æ•°é‡
    parse_success = sum(1 for r in results if r['policy_pred'] is not None)
    parse_rate = parse_success / total if total > 0 else 0
    
    # åˆå§‹åŒ–æ¯ä¸ªå‚æ•°çš„è¯¯å·®åˆ—è¡¨ï¼ˆä»…å½“æœ‰çœŸå®å€¼æ—¶è®¡ç®—ï¼‰
    param_errors = {param: {'mae': [], 'mse': [], 'relative_error': []} for param in POLICY_PARAMS}
    
    # åˆå§‹åŒ–åˆè§„æ€§ç»Ÿè®¡
    compliance_stats = {
        'total_with_service_type': 0,
        'total_compliant_policies': 0,
        'param_compliance': {param: {'compliant': 0, 'total': 0} for param in POLICY_PARAMS},
        'service_type_stats': {},
        'intent_type_stats': {}
    }
    
    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„è¯¯å·®å’Œåˆè§„æ€§
    for result in results:
        if result['policy_pred'] is None:
            continue
        
        policy_true = result.get('policy_true', {})
        policy_pred = result['policy_pred']
        service_type = result.get('service_type')
        intent_type = result.get('intent_type')
        
        # æ£€æŸ¥é¢„æµ‹policyçš„åˆè§„æ€§
        if service_type:
            compliance_stats['total_with_service_type'] += 1
            pred_compliance = check_policy_compliance(policy_pred, service_type)
            
            if pred_compliance:
                # ç»Ÿè®¡æ•´ä½“åˆè§„æ€§
                if pred_compliance.get('all_compliant', False):
                    compliance_stats['total_compliant_policies'] += 1
                
                # ç»Ÿè®¡æ¯ä¸ªå‚æ•°çš„åˆè§„æ€§
                for param in POLICY_PARAMS:
                    if param in policy_pred:
                        compliance_stats['param_compliance'][param]['total'] += 1
                        if pred_compliance.get(param, {}).get('in_range') == True:
                            compliance_stats['param_compliance'][param]['compliant'] += 1
                
                # æŒ‰æœåŠ¡ç±»å‹ç»Ÿè®¡
                if service_type not in compliance_stats['service_type_stats']:
                    compliance_stats['service_type_stats'][service_type] = {
                        'total': 0,
                        'compliant': 0
                    }
                compliance_stats['service_type_stats'][service_type]['total'] += 1
                if pred_compliance.get('all_compliant', False):
                    compliance_stats['service_type_stats'][service_type]['compliant'] += 1
                
                # æŒ‰æ„å›¾ç±»å‹ç»Ÿè®¡
                if intent_type:
                    if intent_type not in compliance_stats['intent_type_stats']:
                        compliance_stats['intent_type_stats'][intent_type] = {
                            'total': 0,
                            'compliant': 0
                        }
                    compliance_stats['intent_type_stats'][intent_type]['total'] += 1
                    if pred_compliance.get('all_compliant', False):
                        compliance_stats['intent_type_stats'][intent_type]['compliant'] += 1
        
        # è®¡ç®—è¯¯å·®ï¼ˆä»…å½“æœ‰çœŸå®å€¼æ—¶ï¼‰
        if policy_true and len(policy_true) > 0:
            for param in POLICY_PARAMS:
                if param in policy_true and param in policy_pred:
                    true_val = float(policy_true[param])
                    pred_val = float(policy_pred[param])
                    
                    # è®¡ç®—ç»å¯¹è¯¯å·®
                    abs_error = abs(pred_val - true_val)
                    param_errors[param]['mae'].append(abs_error)
                    param_errors[param]['mse'].append(abs_error ** 2)
                    
                    # è®¡ç®—ç›¸å¯¹è¯¯å·®ï¼ˆé¿å…é™¤é›¶ï¼‰
                    if true_val != 0:
                        rel_error = abs_error / abs(true_val)
                        param_errors[param]['relative_error'].append(rel_error)
    
    # è®¡ç®—æ¯ä¸ªå‚æ•°çš„å¹³å‡æŒ‡æ ‡
    metrics = {
        'parse_rate': parse_rate,
        'parse_success': parse_success,
        'total': total,
        'param_metrics': {}
    }
    
    for param in POLICY_PARAMS:
        if len(param_errors[param]['mae']) > 0:
            metrics['param_metrics'][param] = {
                'mae': np.mean(param_errors[param]['mae']),
                'mse': np.mean(param_errors[param]['mse']),
                'rmse': np.sqrt(np.mean(param_errors[param]['mse'])),
                'mean_relative_error': np.mean(param_errors[param]['relative_error']) if len(param_errors[param]['relative_error']) > 0 else None,
                'valid_samples': len(param_errors[param]['mae'])
            }
        else:
            metrics['param_metrics'][param] = {
                'mae': None,
                'mse': None,
                'rmse': None,
                'mean_relative_error': None,
                'valid_samples': 0
            }
    
    # è®¡ç®—æ•´ä½“policyçš„ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æˆ–æ¬§æ°è·ç¦»ï¼Œä»…å½“æœ‰çœŸå®å€¼æ—¶ï¼‰
    policy_similarities = []
    has_ground_truth = any(r.get('policy_true') and len(r.get('policy_true', {})) > 0 for r in results)
    
    if has_ground_truth:
        for result in results:
            if result['policy_pred'] is None:
                continue
            
            policy_true = result.get('policy_true', {})
            policy_pred = result['policy_pred']
            
            if not policy_true or len(policy_true) == 0:
                continue
            
            # æå–æ‰€æœ‰å‚æ•°çš„å‘é‡
            true_vec = []
            pred_vec = []
            for param in POLICY_PARAMS:
                if param in policy_true and param in policy_pred:
                    true_vec.append(float(policy_true[param]))
                    pred_vec.append(float(policy_pred[param]))
            
            if len(true_vec) > 0:
                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                true_vec = np.array(true_vec)
                pred_vec = np.array(pred_vec)
                
                # å½’ä¸€åŒ–
                true_norm = np.linalg.norm(true_vec)
                pred_norm = np.linalg.norm(pred_vec)
                
                if true_norm > 0 and pred_norm > 0:
                    cosine_sim = np.dot(true_vec, pred_vec) / (true_norm * pred_norm)
                    policy_similarities.append(cosine_sim)
                
                # è®¡ç®—å½’ä¸€åŒ–æ¬§æ°è·ç¦»
                # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ (0-1ä¹‹é—´ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸åŒ)
                euclidean_dist = np.linalg.norm(true_vec - pred_vec)
                # ä½¿ç”¨æœ€å¤§å¯èƒ½è·ç¦»è¿›è¡Œå½’ä¸€åŒ–ï¼ˆè¿™é‡Œä½¿ç”¨ç»éªŒå€¼ï¼‰
                max_dist = np.linalg.norm(true_vec) + np.linalg.norm(pred_vec)
                if max_dist > 0:
                    normalized_sim = 1 - min(euclidean_dist / max_dist, 1.0)
                    # ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨æ¬§æ°è·ç¦»
                    result['euclidean_distance'] = euclidean_dist
                    result['cosine_similarity'] = cosine_sim if true_norm > 0 and pred_norm > 0 else None
        
        if len(policy_similarities) > 0:
            metrics['mean_cosine_similarity'] = np.mean(policy_similarities)
        else:
            metrics['mean_cosine_similarity'] = None
    else:
        metrics['mean_cosine_similarity'] = None
    
    # è®¡ç®—åˆè§„æ€§æŒ‡æ ‡
    if compliance_stats['total_with_service_type'] > 0:
        metrics['overall_compliance_rate'] = compliance_stats['total_compliant_policies'] / compliance_stats['total_with_service_type']
        metrics['param_compliance_rates'] = {}
        for param in POLICY_PARAMS:
            total = compliance_stats['param_compliance'][param]['total']
            compliant = compliance_stats['param_compliance'][param]['compliant']
            if total > 0:
                metrics['param_compliance_rates'][param] = compliant / total
            else:
                metrics['param_compliance_rates'][param] = None
        
        # æŒ‰æœåŠ¡ç±»å‹çš„åˆè§„ç‡
        metrics['service_type_compliance'] = {}
        for service_type, stats in compliance_stats['service_type_stats'].items():
            if stats['total'] > 0:
                metrics['service_type_compliance'][service_type] = stats['compliant'] / stats['total']
        
        # æŒ‰æ„å›¾ç±»å‹çš„åˆè§„ç‡
        metrics['intent_type_compliance'] = {}
        for intent_type, stats in compliance_stats['intent_type_stats'].items():
            if stats['total'] > 0:
                metrics['intent_type_compliance'][intent_type] = stats['compliant'] / stats['total']
    else:
        metrics['overall_compliance_rate'] = None
        metrics['param_compliance_rates'] = {}
        metrics['service_type_compliance'] = {}
        metrics['intent_type_compliance'] = {}
    
    metrics['compliance_stats'] = compliance_stats
    metrics['has_ground_truth'] = has_ground_truth
    
    return metrics

def main():
    print("=" * 60)
    print("ğŸš€ Policyæ¨¡å‹æµ‹è¯•å¼€å§‹")
    print("=" * 60)
    
    # æ£€æŸ¥è·¯å¾„
    if not os.path.exists(BASE_MODEL_DIR):
        raise FileNotFoundError(f"åŸºç¡€æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {BASE_MODEL_DIR}")
    
    if not os.path.exists(TEST_DATA_PATH):
        raise FileNotFoundError(f"æµ‹è¯•æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {TEST_DATA_PATH}")
    
    # åŠ è½½æ¨¡å‹
    tokenizer, model = load_model_with_lora(BASE_MODEL_DIR, LORA_MODEL_DIR, GPU_ID)
    print(f"æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}\n")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_data = load_test_data(TEST_DATA_PATH)
    
    # è¿›è¡Œæµ‹è¯•
    print("å¼€å§‹æµ‹è¯•...")
    print("-" * 60)
    
    results = []
    for idx, item in enumerate(test_data, 1):
        # æå–ç”¨æˆ·æ„å›¾ã€æœåŠ¡ç±»å‹å’ŒæœŸæœ›çš„policy
        user_intent, service_type, policy_true = extract_policy_from_data(item)
        
        # æå–æ„å›¾ç±»å‹
        intent_type = None
        if "instruction" in item:
            intent_type = item["instruction"].get("intent_type", None)
        
        if not user_intent:
            print(f"âš ï¸  ç¬¬ {idx} æ¡æµ‹è¯•æ•°æ®ç¼ºå°‘ç”¨æˆ·æ„å›¾ï¼Œå·²è·³è¿‡")
            continue
        
        # æ¨ç†
        try:
            output_text = infer(model, tokenizer, user_intent)
            policy_pred = parse_policy_output(output_text)
        except Exception as e:
            print(f"âš ï¸  ç¬¬ {idx} æ¡æµ‹è¯•å‡ºé”™: {e}")
            policy_pred = None
            output_text = ""
        
        # æ£€æŸ¥é¢„æµ‹policyçš„åˆè§„æ€§
        pred_compliance = None
        if policy_pred is not None and service_type:
            pred_compliance = check_policy_compliance(policy_pred, service_type)
        
        # è®°å½•ç»“æœ
        result = {
            'idx': idx,
            'user_intent': user_intent,
            'service_type': service_type,
            'intent_type': intent_type,
            'policy_true': policy_true,
            'policy_pred': policy_pred,
            'output': output_text,
            'parse_success': policy_pred is not None,
            'pred_compliance': pred_compliance
        }
        results.append(result)
        
        # æ˜¾ç¤ºè¿›åº¦
        if idx % 10 == 0:
            print(f"å·²æµ‹è¯• {idx}/{len(test_data)} æ¡...")
    
    print("-" * 60)
    print("æµ‹è¯•å®Œæˆï¼\n")
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_metrics(results)
    
    # æ˜¾ç¤ºç»“æœ
    print("=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœ")
    print("=" * 60)
    print(f"æ€»æµ‹è¯•æ ·æœ¬æ•°: {metrics['total']}")
    print(f"è§£ææˆåŠŸç‡: {metrics['parse_rate']:.4f} ({metrics['parse_success']}/{metrics['total']})")
    
    if metrics['mean_cosine_similarity'] is not None:
        print(f"å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦: {metrics['mean_cosine_similarity']:.4f}")
    
    # æ˜¾ç¤ºåˆè§„æ€§æŒ‡æ ‡
    if metrics.get('overall_compliance_rate') is not None:
        print(f"\nğŸ“‹ 3GPPæ ‡å‡†åˆè§„æ€§æŒ‡æ ‡:")
        print("-" * 60)
        print(f"æ•´ä½“åˆè§„ç‡: {metrics['overall_compliance_rate']:.4f} ({metrics['compliance_stats']['total_compliant_policies']}/{metrics['compliance_stats']['total_with_service_type']})")
        
        print(f"\nå„å‚æ•°åˆè§„ç‡:")
        for param in POLICY_PARAMS:
            compliance_rate = metrics['param_compliance_rates'].get(param)
            if compliance_rate is not None:
                stats = metrics['compliance_stats']['param_compliance'][param]
                print(f"  {param}: {compliance_rate:.4f} ({stats['compliant']}/{stats['total']})")
        
        if metrics.get('service_type_compliance'):
            print(f"\nå„æœåŠ¡ç±»å‹åˆè§„ç‡:")
            for service_type, rate in sorted(metrics['service_type_compliance'].items()):
                stats = metrics['compliance_stats']['service_type_stats'][service_type]
                print(f"  {service_type}: {rate:.4f} ({stats['compliant']}/{stats['total']})")
        
        if metrics.get('intent_type_compliance'):
            print(f"\nå„æ„å›¾ç±»å‹åˆè§„ç‡:")
            for intent_type, rate in sorted(metrics['intent_type_compliance'].items()):
                stats = metrics['compliance_stats']['intent_type_stats'][intent_type]
                print(f"  {intent_type}: {rate:.4f} ({stats['compliant']}/{stats['total']})")
    
    # ä»…å½“æœ‰çœŸå®å€¼æ—¶æ‰æ˜¾ç¤ºè¯¯å·®æŒ‡æ ‡
    if metrics.get('has_ground_truth'):
        print("\nå„Policyå‚æ•°è¯¯å·®æŒ‡æ ‡:")
        print("-" * 60)
        for param in POLICY_PARAMS:
            param_metric = metrics['param_metrics'][param]
            if param_metric['valid_samples'] > 0:
                print(f"\n{param}:")
                print(f"  æœ‰æ•ˆæ ·æœ¬æ•°: {param_metric['valid_samples']}")
                print(f"  MAE (å¹³å‡ç»å¯¹è¯¯å·®): {param_metric['mae']:.6f}")
                print(f"  MSE (å‡æ–¹è¯¯å·®): {param_metric['mse']:.6f}")
                print(f"  RMSE (å‡æ–¹æ ¹è¯¯å·®): {param_metric['rmse']:.6f}")
                if param_metric['mean_relative_error'] is not None:
                    print(f"  å¹³å‡ç›¸å¯¹è¯¯å·®: {param_metric['mean_relative_error']:.4%}")
                # æ˜¾ç¤ºåˆè§„ç‡ï¼ˆå¦‚æœæœ‰ï¼‰
                if metrics.get('param_compliance_rates', {}).get(param) is not None:
                    print(f"  3GPPåˆè§„ç‡: {metrics['param_compliance_rates'][param]:.4f}")
            else:
                print(f"\n{param}: æ— æœ‰æ•ˆæ ·æœ¬")
    else:
        print("\nâš ï¸  æ³¨æ„: æµ‹è¯•æ•°æ®ä¸­æ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œæ— æ³•è®¡ç®—è¯¯å·®æŒ‡æ ‡")
    
    print("=" * 60)
    
    # æ˜¾ç¤ºé”™è¯¯æ ·æœ¬
    print("\nâŒ è§£æå¤±è´¥æ ·æœ¬åˆ†æ:")
    print("-" * 60)
    
    parse_failures = [r for r in results if not r['parse_success']]
    print(f"\nè§£æå¤±è´¥æ•°é‡: {len(parse_failures)}")
    for r in parse_failures[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"\n  æ ·æœ¬ {r['idx']}:")
        print(f"  ç”¨æˆ·æ„å›¾: {r['user_intent'][:80]}...")
        print(f"  æ¨¡å‹è¾“å‡º: {r['output'][:200]}...")
    
    # æ˜¾ç¤ºé¢„æµ‹è¯¯å·®è¾ƒå¤§çš„æ ·æœ¬ï¼ˆä»…å½“æœ‰çœŸå®å€¼æ—¶ï¼‰
    if metrics.get('has_ground_truth'):
        print("\nâš ï¸  é¢„æµ‹è¯¯å·®è¾ƒå¤§æ ·æœ¬ (å‰5ä¸ª):")
        print("-" * 60)
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æ€»è¯¯å·®
        for result in results:
            if result['policy_pred'] is None:
                result['total_error'] = float('inf')
                result['euclidean_distance'] = float('inf')
                continue
            
            total_error = 0
            policy_true = result.get('policy_true', {})
            policy_pred = result['policy_pred']
            
            if not policy_true or len(policy_true) == 0:
                result['total_error'] = None
                result['euclidean_distance'] = None
                continue
            
            # è®¡ç®—æ‰€æœ‰å‚æ•°çš„è¯¯å·®
            true_vec = []
            pred_vec = []
            for param in POLICY_PARAMS:
                if param in policy_true and param in policy_pred:
                    true_val = float(policy_true[param])
                    pred_val = float(policy_pred[param])
                    true_vec.append(true_val)
                    pred_vec.append(pred_val)
                    total_error += abs(pred_val - true_val) ** 2
            
            result['total_error'] = np.sqrt(total_error) if total_error > 0 else 0
            
            # è®¡ç®—æ¬§æ°è·ç¦»
            if len(true_vec) > 0:
                result['euclidean_distance'] = np.linalg.norm(np.array(true_vec) - np.array(pred_vec))
            else:
                result['euclidean_distance'] = float('inf')
        
        # æŒ‰è¯¯å·®æ’åº
        error_samples = sorted([r for r in results if r.get('policy_pred') is not None and r.get('total_error') is not None], 
                              key=lambda x: x.get('total_error', float('inf')), reverse=True)
        
        for r in error_samples[:5]:
            print(f"\n  æ ·æœ¬ {r['idx']} (æ€»è¯¯å·®: {r.get('total_error', 0):.4f}):")
            print(f"  æœåŠ¡ç±»å‹: {r.get('service_type', 'æœªçŸ¥')}")
            print(f"  ç”¨æˆ·æ„å›¾: {r['user_intent'][:80]}...")
            if r.get('policy_true'):
                print(f"  çœŸå®Policy: {json.dumps(r['policy_true'], ensure_ascii=False, indent=2)}")
            print(f"  é¢„æµ‹Policy: {json.dumps(r['policy_pred'], ensure_ascii=False, indent=2)}")
            if r.get('pred_compliance'):
                all_compliant = r['pred_compliance'].get('all_compliant', False)
                print(f"  åˆè§„æ€§: {'âœ… å®Œå…¨åˆè§„' if all_compliant else 'âŒ éƒ¨åˆ†ä¸åˆè§„'}")
                print(f"  åˆè§„ç‡: {r['pred_compliance'].get('overall_compliance_rate', 0):.2%}")
    
    # æ˜¾ç¤ºä¸åˆè§„æ ·æœ¬
    print("\nâŒ ä¸åˆè§„æ ·æœ¬åˆ†æ (å‰5ä¸ª):")
    print("-" * 60)
    non_compliant_samples = [r for r in results if r.get('pred_compliance') and not r['pred_compliance'].get('all_compliant', True)]
    for r in non_compliant_samples[:5]:
        print(f"\n  æ ·æœ¬ {r['idx']}:")
        print(f"  æœåŠ¡ç±»å‹: {r.get('service_type', 'æœªçŸ¥')}")
        print(f"  ç”¨æˆ·æ„å›¾: {r['user_intent'][:80]}...")
        print(f"  é¢„æµ‹Policy: {json.dumps(r['policy_pred'], ensure_ascii=False, indent=2)}")
        print(f"  ä¸åˆè§„å‚æ•°:")
        for param in POLICY_PARAMS:
            if param in r.get('pred_compliance', {}):
                param_info = r['pred_compliance'][param]
                if param_info.get('in_range') == False:
                    rule = param_info.get('rule')
                    value = param_info.get('value')
                    if isinstance(rule, list) and len(rule) == 2:
                        print(f"    {param}: {value} (èŒƒå›´: [{rule[0]}, {rule[1]}])")
                    else:
                        print(f"    {param}: {value} (è¦æ±‚: {rule})")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_file = "test_policy_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'metrics': metrics,
            'results': results
        }, f, ensure_ascii=False, indent=2, default=str)
    print(f"\nâœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    main()

